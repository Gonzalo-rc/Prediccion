---
title: "NBA_Regularization"
author: "Gonzalo Rodríguez Cañada"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

## Objetivo del trabajo
Responder las siguientes preguntas
¿Hay una fuerte relación entre los datos de los jugadores y sus salarios?
 La respuesta es absolutamente sí, pero ¿cuánto?

## Descripción de las variables

En primer lugar es importante conocer el dataset que tenemos en tre manos por
ello se explicarán las variables de la base de datos:

**Player**: son el nombre y apellido del jugador

**Salary**: Es el salario que percibe el jugador

**NBA_Country** : Es el país de procedencia del jugador

**NBA_DraftNumber**:El número en el que el jugador fue drafteado

**Age**: Es la edad del jugador

**Tm**:Equipo para el juega

**G**: Número de partidos jugados

**MP**: Minutos jugados

**PER**: El PER es una estadística avanzada usada en la NBA, para medir 
el rendimiento de un jugador la media es 15

**TS%**: tanto por ciento de tiros acertados

**3PAr** : Tasa de Intento de 3 puntos Porcentaje 

**FTr** : Tasa de intentos de lanzamiento libre Número de intentos FT por intento FG


**ORB%**:  Porcentaje de rebote ofensivo Una estimación del porcentaje de rebotes ofensivos disponibles que un jugador agarró mientras estaba en el suelo.

**DRB% **: Porcentaje de rebote defensivo Una estimación del porcentaje de rebotes defensivos disponibles que un jugador agarró mientras estaba en el suelo.

**TRB%** : Porcentaje de rebote total Estimación del porcentaje de rebotes disponibles que un jugador agarró mientras estaba en el suelo.

**AST**:Porcentaje de asistencia. Estimación del porcentaje de canastas de campo de un compañero de equipo que un jugador asistió mientras estaba en la pista.

**STL%**:Porcentaje de robo. 
Una estimación del porcentaje de posesiones del oponente que terminan con un robo por parte del jugador mientras estaba en la pista

**BLK**:Porcentaje de tapón. 

Una estimación del porcentaje de intentos de canasta  de dos puntos del oponente bloqueados por el jugador mientras estaba en la pista.

**TOV%**: Porcentaje de pérdidas por cada 100 posesiones.

**USG**: Porcentaje de uso. Una estimación del porcentaje de jugadas en equipo utilizadas por un jugador mientras estaba en el suelo.

**OWS**: Acciones de Ganancias Ofensivas Una estimación del número de ganancias aportadas por un jugador debido a su ataque.

**DWS**:Acciones de victoria defensiva. Estimación del número de victorias aportadas por un jugador debido a su defensa.

**WS**:Acciones ganadoras Una estimación del número de ganancias aportadas por un jugador.

**WS/48**: Acciones de victoria por 48 minutos. Una estimación del número de victorias aportadas por un jugador por 48 minutos (el promedio de la liga es aproximadamente .100)

**OBPM**:Cuadro ofensivo más/menos. Un cálculo de los puntos ofensivos por cada 100 posesiones que un jugador aportó por encima del promedio de la liga, traducido a un equipo promedio.

**DBPM**: Caja defensiva más/menos.  Una estimación de la puntuación de caja de los puntos defensivos por cada 100 posesiones que un jugador aportó por encima del promedio de un jugador de la liga, traducido a un equipo promedio.

**BPM**:Caja Más/Menos Una estimación de la puntuación de caja de los puntos por cada 100 posesiones que un jugador aportó por encima del promedio de un jugador de la liga, traducido a un equipo promedio.

**VORP**: Valor sobre el jugador de reemplazo Una estimación de la puntuación de caja de los puntos por cada 100 posesiones del equipo que un jugador contribuyó por encima del nivel de reemplazo (-2.0), traducido a un equipo promedio y prorrateado a una temporada de 82 juegos.


# Cargamos librerias
```{r echo=FALSE,warning= FALSE, message=FALSE}
library(here) # Comentar
library(tidyverse)
library(janitor) # Clean names
library(skimr) # Beautiful Summarize
library(magrittr) # Pipe operators
library(corrplot) # Correlations
library(ggcorrplot)  # Correlations
library(PerformanceAnalytics) # Correlations
library(leaps) # Model selection
library(MASS)
library(dplyr)
library(readr)
library(gvlma)
library(MASS)
library(car)
library(glmnet)
library(boot)
library(leaps)
library(rsample)
```

## Cargamos los datos

```{r Carga de datos,include=FALSE}
raw_data <-  read.csv("../data/nba.csv")
colnames(raw_data)

raw_data %<>% clean_names()
colnames(raw_data) #Nombre de columna
```

#Limpiamos los datos

```{r}
raw_data %<>% clean_names()
colnames(raw_data)
# delete duplicate
# Remove duplicate rows of the dataframe
raw_data %<>% distinct(player,.keep_all= TRUE)
# delete NA's
raw_data %<>% drop_na() #buscamos el de menor std respecto a su media
```
## Pasamos a logaritmo el salario

```{r}
log_data <- raw_data %>% mutate(salary=log(salary))

```
# Hacemos división del dataset
```{r}
set.seed(03112020)

# Vamos a usar el 70% del dataset
nba_split <- initial_split(log_data, prop = .7, strata = "salary")
#Definimos training y test dataset 
nba_tr <- training(nba_split)
nba_test  <- testing(nba_split)

```

+ Eliminamos el intercepto

```{r}

nba_tr_x <- model.matrix(salary ~ . -player -nba_country -tm, data = log_data)[, -1]
nba_tr_y <- log_data$salary
nba_test_x <- model.matrix(salary ~ . -player -nba_country -tm, data = log_data)[, -1]
nba_test_y <- log_data$salary
```


# Elastic net
```{r}
# Mantenemos los folds en la muestra
fold_id <- sample(1:10, size = length(nba_tr_y), replace=TRUE)

# Miramos entre los grupos de alphas.

tuning_grid <- tibble::tibble(
  alpha      = seq(0, 1, by = 0.05),
  mse_min    = NA,
  mse_1se    = NA,
  lambda_min = NA,
  lambda_1se = NA
)
tuning_grid

```

+ Hacemos crossvalidation para cada alpha
```{r}
for(i in seq_along(tuning_grid$alpha)) {
  

  fit <- cv.glmnet(nba_tr_x, nba_tr_y, alpha = tuning_grid$alpha[i], foldid = fold_id)
  
  # Se sacan los minimun square errors y lambdas
  tuning_grid$mse_min[i]    <- fit$cvm[fit$lambda == fit$lambda.min]
  tuning_grid$mse_1se[i]    <- fit$cvm[fit$lambda == fit$lambda.1se]
  tuning_grid$lambda_min[i] <- fit$lambda.min
  tuning_grid$lambda_1se[i] <- fit$lambda.1se
}
tuning_grid
```

+ El que menor que menor lambda nos da es el alpha correspondiente a 1 que corresponde a lasso.


### Calculo del error asociado al lasso con el training
```{r}
cv_lasso   <- cv.glmnet(nba_tr_x, nba_tr_y, alpha = 1.0)
min(cv_lasso$cvm)
```


### Prediccion y calculo del error con el dataset de test
```{r}


pred <- predict(cv_lasso, s = cv_lasso$lambda.min, nba_test_x)
mean((nba_test_y - pred)^2) #el error de la prediccion es menor que 

```


